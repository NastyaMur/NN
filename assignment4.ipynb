{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwEL0Ix900sX"
   },
   "source": [
    "# Лабораторная работа 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wydtefmO00sg"
   },
   "source": [
    "Tensorflow 2.x\n",
    "\n",
    "1) Подготовка данных\n",
    "\n",
    "2) Использование Keras Model API\n",
    "\n",
    "3) Использование Keras Sequential + Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBUm8ctY00sh"
   },
   "source": [
    "https://www.tensorflow.org/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4gNt5wn00sj"
   },
   "source": [
    "Для выполнения лабораторной работы необходимо установить tensorflow версии 2.0 или выше .\n",
    "\n",
    "Рекомендуется использовать возможности Colab'а по обучению моделей на GPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n9J2apq900sm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\volce\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yb9_MVk_1Qvc"
   },
   "outputs": [],
   "source": [
    "USE_GPU = False\n",
    "device = '/device:GPU:0' if USE_GPU else '/cpu:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yjVO6t2k2t5Y"
   },
   "outputs": [],
   "source": [
    "print_every = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QE--OYJi00sp"
   },
   "source": [
    "# Подготовка данных\n",
    "Загрузите набор данных из предыдущей лабораторной работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7m40FTUR00sq",
    "outputId": "92fc62c7-8556-42ad-aa98-ff145af8be32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 28, 28, 1)\n",
      "Train labels shape:  (49000,) int32\n",
      "Validation data shape:  (1000, 28, 28, 1)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 28, 28, 1)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "def load_mnist(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    \"\"\"\n",
    "    Fetch the CIFAR-10 dataset from the web and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.\n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n",
    "    mnist = tf.keras.datasets.mnist.load_data()\n",
    "    (X_train, y_train), (X_test, y_test) = mnist\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean pixel and divide by std\n",
    "    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
    "    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
    "    X_train = (X_train - mean_pixel) / std_pixel\n",
    "    X_val = (X_val - mean_pixel) / std_pixel\n",
    "    X_test = (X_test - mean_pixel) / std_pixel\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# If there are errors with SSL downloading involving self-signed certificates,\n",
    "# it may be that your Python version was recently installed on the current machine.\n",
    "# See: https://github.com/tensorflow/tensorflow/issues/10779\n",
    "# To fix, run the command: /Applications/Python\\ 3.7/Install\\ Certificates.command\n",
    "#   ...replacing paths as necessary.\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "NHW = (0, 1, 2)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_mnist()\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_val = X_val.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "SkfwKpCJ00sr"
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Construct a Dataset object to iterate over data X and labels y\n",
    "\n",
    "        Inputs:\n",
    "        - X: Numpy array of data, of any shape\n",
    "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
    "        - batch_size: Integer giving number of elements per minibatch\n",
    "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
    "\n",
    "\n",
    "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
    "test_dset = Dataset(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9VNIN1JB00ss",
    "outputId": "4e3cbbe8-da70-47f9-8173-4b17ac4cc2d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (64, 28, 28, 1) (64,)\n",
      "1 (64, 28, 28, 1) (64,)\n",
      "2 (64, 28, 28, 1) (64,)\n",
      "3 (64, 28, 28, 1) (64,)\n",
      "4 (64, 28, 28, 1) (64,)\n",
      "5 (64, 28, 28, 1) (64,)\n",
      "6 (64, 28, 28, 1) (64,)\n"
     ]
    }
   ],
   "source": [
    "# We can iterate through a dataset like this:\n",
    "for t, (x, y) in enumerate(train_dset):\n",
    "    print(t, x.shape, y.shape)\n",
    "    if t > 5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2YJcBuY00su"
   },
   "source": [
    "#  Keras Model Subclassing API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHb91Q9d00su"
   },
   "source": [
    "\n",
    "Для реализации собственной модели с помощью Keras Model Subclassing API необходимо выполнить следующие шаги:\n",
    "\n",
    "1) Определить новый класс, который является наследником tf.keras.Model.\n",
    "\n",
    "2) В методе __init__() определить все необходимые слои из модуля tf.keras.layer\n",
    "\n",
    "3) Реализовать прямой проход в методе call() на основе слоев, объявленных в __init__()\n",
    "\n",
    "Ниже приведен пример использования keras API для определения двухслойной полносвязной сети.\n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-JjoN1Vw00su",
    "outputId": "36c02bdf-072d-417d-b627-5bfcb4b2d2b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "class TwoLayerFC(tf.keras.Model):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super(TwoLayerFC, self).__init__()\n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0, seed=42)\n",
    "        self.fc1 = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.fc2 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_TwoLayerFC():\n",
    "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "    x = tf.zeros((64, input_size))\n",
    "    model = TwoLayerFC(hidden_size, num_classes)\n",
    "    with tf.device(device):\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "\n",
    "test_TwoLayerFC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euXqeEOH00sv"
   },
   "source": [
    "Реализуйте трехслойную CNN для вашей задачи классификации.\n",
    "\n",
    "Архитектура сети:\n",
    "    \n",
    "1. Сверточный слой (5 x 5 kernels, zero-padding = 'same')\n",
    "2. Функция активации ReLU\n",
    "3. Сверточный слой (3 x 3 kernels, zero-padding = 'same')\n",
    "4. Функция активации ReLU\n",
    "5. Полносвязный слой\n",
    "6. Функция активации Softmax\n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2D\n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "fhj-jCDb00sv"
   },
   "outputs": [],
   "source": [
    "class ThreeLayerConvNet(tf.keras.Model):\n",
    "    def __init__(self, channel_1, channel_2, num_classes):\n",
    "        super(ThreeLayerConvNet, self).__init__()\n",
    "        ########################################################################\n",
    "        # TODO: Implement the __init__ method for a three-layer ConvNet. You   #\n",
    "        # should instantiate layer objects to be used in the forward pass.     #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(channel_1, (5, 5), padding='same', activation='relu')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(channel_2, (3, 3), padding='same', activation='relu')\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        scores = None\n",
    "        ########################################################################\n",
    "        # TODO: Implement the forward pass for a three-layer ConvNet. You      #\n",
    "        # should use the layer objects defined in the __init__ method.         #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        scores = self.conv1(x)\n",
    "        scores = self.conv2(scores)\n",
    "        scores = self.flatten(scores)\n",
    "        scores = self.fc(scores)\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNF5eIfL00sw",
    "outputId": "5578ea50-ad83-4af6-fb38-469a9850b2b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "def test_ThreeLayerConvNet():\n",
    "    channel_1, channel_2, num_classes = 12, 8, 10\n",
    "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
    "    with tf.device(device):\n",
    "        x = tf.zeros((64, 3, 32, 32))\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "\n",
    "test_ThreeLayerConvNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwHw8q_f00sw"
   },
   "source": [
    "Пример реализации процесса обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "p-4cw3gt00sw"
   },
   "outputs": [],
   "source": [
    "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False):\n",
    "    \"\"\"\n",
    "    Simple training loop for use with models defined using tf.keras. It trains\n",
    "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
    "    accuracy on the CIFAR-10 validation set.\n",
    "\n",
    "    Inputs:\n",
    "    - model_init_fn: A function that takes no parameters; when called it\n",
    "      constructs the model we want to train: model = model_init_fn()\n",
    "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
    "      constructs the Optimizer object we will use to optimize the model:\n",
    "      optimizer = optimizer_init_fn()\n",
    "    - num_epochs: The number of epochs to train for\n",
    "\n",
    "    Returns: Nothing, but prints progress during trainingn\n",
    "    \"\"\"\n",
    "    with tf.device(device):\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "        model = model_init_fn()\n",
    "        optimizer = optimizer_init_fn()\n",
    "\n",
    "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "        val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
    "\n",
    "        t = 0\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n",
    "            train_loss.reset_states()\n",
    "            train_accuracy.reset_states()\n",
    "\n",
    "            for x_np, y_np in train_dset:\n",
    "                with tf.GradientTape() as tape:\n",
    "\n",
    "                    # Use the model function to build the forward pass.\n",
    "                    scores = model(x_np, training=is_training)\n",
    "                    loss = loss_fn(y_np, scores)\n",
    "\n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "                    # Update the metrics\n",
    "                    train_loss.update_state(loss)\n",
    "                    train_accuracy.update_state(y_np, scores)\n",
    "\n",
    "                    if t % print_every == 0:\n",
    "                        val_loss.reset_states()\n",
    "                        val_accuracy.reset_states()\n",
    "                        for test_x, test_y in val_dset:\n",
    "                            # During validation at end of epoch, training set to False\n",
    "                            prediction = model(test_x, training=False)\n",
    "                            t_loss = loss_fn(test_y, prediction)\n",
    "\n",
    "                            val_loss.update_state(t_loss)\n",
    "                            val_accuracy.update_state(test_y, prediction)\n",
    "\n",
    "                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n",
    "                        print (template.format(t, epoch+1,\n",
    "                                             train_loss.result(),\n",
    "                                             train_accuracy.result()*100,\n",
    "                                             val_loss.result(),\n",
    "                                             val_accuracy.result()*100))\n",
    "                    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhoNxmLf00sx",
    "outputId": "a31ae62d-6675-4677-f2b8-a2ec6fa7c00f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.061091423034668, Accuracy: 7.8125, Val Loss: 2.6353776454925537, Val Accuracy: 20.100000381469727\n",
      "Iteration 100, Epoch 1, Loss: 0.6486901640892029, Accuracy: 80.30631256103516, Val Loss: 0.5465362668037415, Val Accuracy: 83.20000457763672\n",
      "Iteration 200, Epoch 1, Loss: 0.5134939551353455, Accuracy: 84.65484619140625, Val Loss: 0.44879984855651855, Val Accuracy: 86.29999542236328\n",
      "Iteration 300, Epoch 1, Loss: 0.45332732796669006, Accuracy: 86.5188980102539, Val Loss: 0.4038299024105072, Val Accuracy: 87.30000305175781\n",
      "Iteration 400, Epoch 1, Loss: 0.40937238931655884, Accuracy: 87.87017059326172, Val Loss: 0.3598787486553192, Val Accuracy: 89.20000457763672\n",
      "Iteration 500, Epoch 1, Loss: 0.3856959044933319, Accuracy: 88.60404205322266, Val Loss: 0.34413355588912964, Val Accuracy: 90.20000457763672\n",
      "Iteration 600, Epoch 1, Loss: 0.361906498670578, Accuracy: 89.31208038330078, Val Loss: 0.33807024359703064, Val Accuracy: 90.80000305175781\n",
      "Iteration 700, Epoch 1, Loss: 0.3444284200668335, Accuracy: 89.8537826538086, Val Loss: 0.31216293573379517, Val Accuracy: 90.80000305175781\n"
     ]
    }
   ],
   "source": [
    "hidden_size, num_classes = 4000, 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    return TwoLayerFC(hidden_size, num_classes)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dPtCbHS00sx"
   },
   "source": [
    "Обучите трехслойную CNN. В tf.keras.optimizers.SGD укажите Nesterov momentum = 0.9 .\n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers/SGD\n",
    "\n",
    "Значение accuracy на валидационной выборке после 1 эпохи обучения должно быть > 50% ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VUOCsUZX00sy",
    "outputId": "9079bec5-5121-414c-a555-c2b841888d63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 2.3081676959991455, Accuracy: 4.6875, Val Loss: 2.2887723445892334, Val Accuracy: 10.100000381469727\n",
      "Iteration 100, Epoch 1, Loss: 0.6771867275238037, Accuracy: 80.07425689697266, Val Loss: 0.4905747175216675, Val Accuracy: 83.70000457763672\n",
      "Iteration 200, Epoch 1, Loss: 0.5065358281135559, Accuracy: 85.3078384399414, Val Loss: 0.3975633382797241, Val Accuracy: 87.69999694824219\n",
      "Iteration 300, Epoch 1, Loss: 0.4143221974372864, Accuracy: 87.92566680908203, Val Loss: 0.23670873045921326, Val Accuracy: 93.30000305175781\n",
      "Iteration 400, Epoch 1, Loss: 0.349885493516922, Accuracy: 89.73270416259766, Val Loss: 0.22762106359004974, Val Accuracy: 92.69999694824219\n",
      "Iteration 500, Epoch 1, Loss: 0.31137359142303467, Accuracy: 90.89633178710938, Val Loss: 0.1932782381772995, Val Accuracy: 93.9000015258789\n",
      "Iteration 600, Epoch 1, Loss: 0.27978163957595825, Accuracy: 91.77932739257812, Val Loss: 0.20306076109409332, Val Accuracy: 93.4000015258789\n",
      "Iteration 700, Epoch 1, Loss: 0.25597891211509705, Accuracy: 92.49063873291016, Val Loss: 0.14911282062530518, Val Accuracy: 94.19999694824219\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "channel_1, channel_2, num_classes = 32, 16, 10\n",
    "\n",
    "def model_init_fn():\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBDDTsda00sy"
   },
   "source": [
    "# Использование Keras Sequential API для реализации последовательных моделей.\n",
    "\n",
    "Пример для полносвязной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xE6Jixvr00sy",
    "outputId": "c2cab031-574a-4d00-ba15-54562c00b1bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.0636892318725586, Accuracy: 9.375, Val Loss: 2.8174750804901123, Val Accuracy: 20.600000381469727\n",
      "Iteration 100, Epoch 1, Loss: 0.6536769270896912, Accuracy: 80.81682586669922, Val Loss: 0.5527722835540771, Val Accuracy: 82.0\n",
      "Iteration 200, Epoch 1, Loss: 0.5154412984848022, Accuracy: 85.02798461914062, Val Loss: 0.4694288671016693, Val Accuracy: 85.9000015258789\n",
      "Iteration 300, Epoch 1, Loss: 0.4560350179672241, Accuracy: 86.73172760009766, Val Loss: 0.41941115260124207, Val Accuracy: 87.0\n",
      "Iteration 400, Epoch 1, Loss: 0.41096195578575134, Accuracy: 88.06889343261719, Val Loss: 0.38207271695137024, Val Accuracy: 89.0999984741211\n",
      "Iteration 500, Epoch 1, Loss: 0.38665854930877686, Accuracy: 88.7724609375, Val Loss: 0.3638768196105957, Val Accuracy: 89.60000610351562\n",
      "Iteration 600, Epoch 1, Loss: 0.3633613884449005, Accuracy: 89.39008331298828, Val Loss: 0.34729209542274475, Val Accuracy: 90.30000305175781\n",
      "Iteration 700, Epoch 1, Loss: 0.34644562005996704, Accuracy: 89.88721466064453, Val Loss: 0.32195162773132324, Val Accuracy: 90.5999984741211\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    input_shape = (28, 28, 1)\n",
    "    hidden_layer_size, num_classes = 4000, 10\n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "    layers = [\n",
    "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(hidden_layer_size, activation='relu',\n",
    "                              kernel_initializer=initializer),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                              kernel_initializer=initializer),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24cr_CzH00sy"
   },
   "source": [
    "Альтернативный менее гибкий способ обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zW7EGVlQ00sz",
    "outputId": "d7e2c193-cc41-4100-ae0e-d267db1faf9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\volce\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\volce\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "766/766 [==============================] - 19s 23ms/step - loss: 0.3399 - sparse_categorical_accuracy: 0.8991 - val_loss: 0.3122 - val_sparse_categorical_accuracy: 0.9140\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2242 - sparse_categorical_accuracy: 0.9346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2242462933063507, 0.9345999956130981]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IU3CgwL00sz"
   },
   "source": [
    "Перепишите реализацию трехслойной CNN с помощью tf.keras.Sequential API . Обучите модель двумя способами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foZ4OpDL00sz",
    "outputId": "7b2aa94a-c3f6-4265-9f83-24a5decb4466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\volce\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Iteration 0, Epoch 1, Loss: 2.3050031661987305, Accuracy: 12.5, Val Loss: 2.3038103580474854, Val Accuracy: 10.59999942779541\n",
      "Iteration 100, Epoch 1, Loss: 2.2718451023101807, Accuracy: 12.979578971862793, Val Loss: 2.2375638484954834, Val Accuracy: 17.399999618530273\n",
      "Iteration 200, Epoch 1, Loss: 2.2371981143951416, Accuracy: 18.11256217956543, Val Loss: 2.1753196716308594, Val Accuracy: 28.400001525878906\n",
      "Iteration 300, Epoch 1, Loss: 2.2043821811676025, Accuracy: 25.47757339477539, Val Loss: 2.110020160675049, Val Accuracy: 46.599998474121094\n",
      "Iteration 400, Epoch 1, Loss: 2.1681740283966064, Accuracy: 32.8125, Val Loss: 2.032646894454956, Val Accuracy: 57.099998474121094\n",
      "Iteration 500, Epoch 1, Loss: 2.1296353340148926, Accuracy: 39.115516662597656, Val Loss: 1.942175030708313, Val Accuracy: 61.19999694824219\n",
      "Iteration 600, Epoch 1, Loss: 2.0857419967651367, Accuracy: 44.10877990722656, Val Loss: 1.8324133157730103, Val Accuracy: 65.69999694824219\n",
      "Iteration 700, Epoch 1, Loss: 2.0361745357513428, Accuracy: 47.83122253417969, Val Loss: 1.6996073722839355, Val Accuracy: 69.0999984741211\n"
     ]
    }
   ],
   "source": [
    "def model_init_fn():\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # TODO: Construct a three-layer ConvNet using tf.keras.Sequential.         #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        # The first conv layer\n",
    "        tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "        # The first pooling layer\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        # The second conv layer\n",
    "        tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
    "        # The second pooling layer\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        # Flatten data\n",
    "        tf.keras.layers.Flatten(),\n",
    "        # The dense layer with ReLU\n",
    "        tf.keras.layers.Dense(1024, activation='relu'),\n",
    "        # Output layer with softmax \n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                            END OF YOUR CODE                              #\n",
    "    ############################################################################\n",
    "    return model\n",
    "\n",
    "learning_rate = 5e-4\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DaQILHMd00s0",
    "outputId": "b3cdfdf1-3d71-48bd-9c8d-cf8e8f608b75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\volce\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "766/766 [==============================] - 73s 95ms/step - loss: 0.3819 - sparse_categorical_accuracy: 0.8925 - val_loss: 0.1906 - val_sparse_categorical_accuracy: 0.9410\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.1210 - sparse_categorical_accuracy: 0.9669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12101379036903381, 0.9668999910354614]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05p4MrdA00s0"
   },
   "source": [
    "# Использование Keras Functional API\n",
    "\n",
    "Для реализации более сложных архитектур сети с несколькими входами/выходами, повторным использованием слоев, \"остаточными\" связями (residual connections) необходимо явно указать входные и выходные тензоры.\n",
    "\n",
    "Ниже представлен пример для полносвязной сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0PZKJvMk00s0",
    "outputId": "51c2dfd6-a378-4a9d-da79-7d8d10687119"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "def two_layer_fc_functional(input_shape, hidden_size, num_classes):\n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    flattened_inputs = tf.keras.layers.Flatten()(inputs)\n",
    "    fc1_output = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
    "                                 kernel_initializer=initializer)(flattened_inputs)\n",
    "    scores = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                             kernel_initializer=initializer)(fc1_output)\n",
    "\n",
    "    # Instantiate the model given inputs and outputs.\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=scores)\n",
    "    return model\n",
    "\n",
    "def test_two_layer_fc_functional():\n",
    "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "    input_shape = (50,)\n",
    "\n",
    "    x = tf.zeros((64, input_size))\n",
    "    model = two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
    "\n",
    "    with tf.device(device):\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "\n",
    "test_two_layer_fc_functional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "siecnw5w00s0",
    "outputId": "afd2f178-6181-4257-a39c-714acbb9a0c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 2.691138744354248, Accuracy: 9.375, Val Loss: 2.4658114910125732, Val Accuracy: 18.299999237060547\n",
      "Iteration 100, Epoch 1, Loss: 0.6254281997680664, Accuracy: 81.0643539428711, Val Loss: 0.5445429682731628, Val Accuracy: 81.9000015258789\n",
      "Iteration 200, Epoch 1, Loss: 0.5011837482452393, Accuracy: 84.98912048339844, Val Loss: 0.4637463688850403, Val Accuracy: 85.69999694824219\n",
      "Iteration 300, Epoch 1, Loss: 0.44794031977653503, Accuracy: 86.64867401123047, Val Loss: 0.40109431743621826, Val Accuracy: 88.30000305175781\n",
      "Iteration 400, Epoch 1, Loss: 0.40599456429481506, Accuracy: 87.93640899658203, Val Loss: 0.35908541083335876, Val Accuracy: 89.60000610351562\n",
      "Iteration 500, Epoch 1, Loss: 0.38384509086608887, Accuracy: 88.61651611328125, Val Loss: 0.34215793013572693, Val Accuracy: 90.30000305175781\n",
      "Iteration 600, Epoch 1, Loss: 0.36028924584388733, Accuracy: 89.35368347167969, Val Loss: 0.33608728647232056, Val Accuracy: 90.80000305175781\n",
      "Iteration 700, Epoch 1, Loss: 0.34357646107673645, Accuracy: 89.85601043701172, Val Loss: 0.31183871626853943, Val Accuracy: 91.0\n"
     ]
    }
   ],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "hidden_size, num_classes = 4000, 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    return two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjCqJtE800s1"
   },
   "source": [
    "Поэкспериментируйте с архитектурой сверточной сети. Для вашего набора данных вам необходимо получить как минимум 70% accuracy на валидационной выборке за 10 эпох обучения. Опишите все эксперименты и сделайте выводы (без выполнения данного пункта работы приниматься не будут).\n",
    "\n",
    "Эспериментируйте с архитектурой, гиперпараметрами, функцией потерь, регуляризацией, методом оптимизации.  \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/BatchNormalization#methods https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dropout#methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eBqPjH7v00s1",
    "outputId": "b47e880e-7438-40fa-b94a-f11a2b044153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 2.351034641265869, Accuracy: 15.625, Val Loss: 2.2210841178894043, Val Accuracy: 19.100000381469727\n",
      "Iteration 700, Epoch 1, Loss: 0.1622346192598343, Accuracy: 95.27461242675781, Val Loss: 0.1292656660079956, Val Accuracy: 96.0\n",
      "Iteration 1400, Epoch 2, Loss: 0.04549592360854149, Accuracy: 98.59497833251953, Val Loss: 0.09731973707675934, Val Accuracy: 96.5999984741211\n",
      "Iteration 2100, Epoch 3, Loss: 0.03049553744494915, Accuracy: 99.00592803955078, Val Loss: 0.1156710684299469, Val Accuracy: 97.19999694824219\n",
      "Iteration 2800, Epoch 4, Loss: 0.02283533103764057, Accuracy: 99.1861343383789, Val Loss: 0.09055744856595993, Val Accuracy: 97.69999694824219\n",
      "Iteration 3500, Epoch 5, Loss: 0.012596665881574154, Accuracy: 99.56736755371094, Val Loss: 0.0892658531665802, Val Accuracy: 97.69999694824219\n",
      "Iteration 4200, Epoch 6, Loss: 0.01604273170232773, Accuracy: 99.4609146118164, Val Loss: 0.0874805897474289, Val Accuracy: 97.39999389648438\n",
      "Iteration 4900, Epoch 7, Loss: 0.015432555228471756, Accuracy: 99.43647766113281, Val Loss: 0.07431509345769882, Val Accuracy: 98.0\n",
      "Iteration 5600, Epoch 8, Loss: 0.010132037103176117, Accuracy: 99.64696502685547, Val Loss: 0.119980588555336, Val Accuracy: 96.69999694824219\n",
      "Iteration 6300, Epoch 9, Loss: 0.0062103914096951485, Accuracy: 99.75614166259766, Val Loss: 0.09959547966718674, Val Accuracy: 97.69999694824219\n",
      "Iteration 7000, Epoch 10, Loss: 0.008070161566138268, Accuracy: 99.6933364868164, Val Loss: 0.09724356979131699, Val Accuracy: 97.5\n"
     ]
    }
   ],
   "source": [
    "class CustomConvNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomConvNet, self).__init__()\n",
    "        ############################################################################\n",
    "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
    "        ############################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(28, (3, 3), activation='relu', input_shape=(28, 28, 1))\n",
    "\n",
    "        self.batchnorm1 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2 = tf.keras.layers.Conv2D(14, (3, 3), activation='relu')\n",
    "\n",
    "        self.batchnorm2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(56, activation='relu')\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.2)\n",
    "        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ############################################################################\n",
    "        #                            END OF YOUR CODE                              #\n",
    "        ############################################################################\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        ############################################################################\n",
    "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
    "        ############################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.batchnorm1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dense1(x)\n",
    "\n",
    "        x = self.dropout1(x, training=training)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense2(x)\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ############################################################################\n",
    "        #                            END OF YOUR CODE                              #\n",
    "        ############################################################################\n",
    "        return x\n",
    "\n",
    "\n",
    "print_every = 700\n",
    "num_epochs = 10\n",
    "\n",
    "model = CustomConvNet()\n",
    "\n",
    "def model_init_fn():\n",
    "    return CustomConvNet()\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    learning_rate = 1e-3\n",
    "    return tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BpDOguj100s2"
   },
   "source": [
    "Опишите все эксперименты, результаты. Сделайте выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2wvNY2URYMf"
   },
   "source": [
    "1. Архитектура сети состоит из: сверточных слоев, droput, flatten, batchnormalization и полносвязных слоев.\n",
    "2. Для выходного слоя тестировались функции активации softmax и sigmoid. Первая показала наилучший результат.\n",
    "3. Среди оптимизаторов лучше всего себя показал Adam - незначительно, но лучше.\n",
    "4. Также модель тестировалась на смене batchnormalization и droput. Модели имели следующие слои:\n",
    "    1. dropuot и batchnormalization (показал наилучшие результаты).\n",
    "    2. droput.\n",
    "    3. batchnormalization.\n",
    "    4. Ни одного .\n",
    "5. Худшим показателем получения accuracy > 70 было 5 эпох.\n",
    "6. В качестве замены ReLU рассматривалась sigmoid, но первая оказала наилучшее влияние.\n",
    "7. По итогам 10 эпох точность модели на валидационной выборке составила более 97%."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
